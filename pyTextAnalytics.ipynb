{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text =  \"Sources in Chennai confirmed that the subject would be the handling of the Assembly polls in the State in 2021. Earlier last week, West Bengal Chief Minister Mamata Banerjee had also met with the IPAC founder and Janata Dal (U) vice president. Incidentally, the IPAC has also handled some aspects of film personality Kamal Haasan’s political campaign under the aegis of his party, Makkal Needhi Maiam (MNM).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sources in Chennai confirmed that the subject would be the handling of the Assembly polls in the State in 2021. Earlier last week, West Bengal Chief Minister Mamata Banerjee had also met with the IPAC founder and Janata Dal (U) vice president. Incidentally, the IPAC has also handled some aspects of film personality Kamal Haasan’s political campaign under the aegis of his party, Makkal Needhi Maiam (MNM).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob\n",
    "from textblob import Word\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Sources', 'in']),\n",
       " WordList(['in', 'Chennai']),\n",
       " WordList(['Chennai', 'confirmed']),\n",
       " WordList(['confirmed', 'that']),\n",
       " WordList(['that', 'the']),\n",
       " WordList(['the', 'subject']),\n",
       " WordList(['subject', 'would']),\n",
       " WordList(['would', 'be']),\n",
       " WordList(['be', 'the']),\n",
       " WordList(['the', 'handling']),\n",
       " WordList(['handling', 'of']),\n",
       " WordList(['of', 'the']),\n",
       " WordList(['the', 'Assembly']),\n",
       " WordList(['Assembly', 'polls']),\n",
       " WordList(['polls', 'in']),\n",
       " WordList(['in', 'the']),\n",
       " WordList(['the', 'State']),\n",
       " WordList(['State', 'in']),\n",
       " WordList(['in', '2021']),\n",
       " WordList(['2021', 'Earlier']),\n",
       " WordList(['Earlier', 'last']),\n",
       " WordList(['last', 'week']),\n",
       " WordList(['week', 'West']),\n",
       " WordList(['West', 'Bengal']),\n",
       " WordList(['Bengal', 'Chief']),\n",
       " WordList(['Chief', 'Minister']),\n",
       " WordList(['Minister', 'Mamata']),\n",
       " WordList(['Mamata', 'Banerjee']),\n",
       " WordList(['Banerjee', 'had']),\n",
       " WordList(['had', 'also']),\n",
       " WordList(['also', 'met']),\n",
       " WordList(['met', 'with']),\n",
       " WordList(['with', 'the']),\n",
       " WordList(['the', 'IPAC']),\n",
       " WordList(['IPAC', 'founder']),\n",
       " WordList(['founder', 'and']),\n",
       " WordList(['and', 'Janata']),\n",
       " WordList(['Janata', 'Dal']),\n",
       " WordList(['Dal', 'U']),\n",
       " WordList(['U', 'vice']),\n",
       " WordList(['vice', 'president']),\n",
       " WordList(['president', 'Incidentally']),\n",
       " WordList(['Incidentally', 'the']),\n",
       " WordList(['the', 'IPAC']),\n",
       " WordList(['IPAC', 'has']),\n",
       " WordList(['has', 'also']),\n",
       " WordList(['also', 'handled']),\n",
       " WordList(['handled', 'some']),\n",
       " WordList(['some', 'aspects']),\n",
       " WordList(['aspects', 'of']),\n",
       " WordList(['of', 'film']),\n",
       " WordList(['film', 'personality']),\n",
       " WordList(['personality', 'Kamal']),\n",
       " WordList(['Kamal', 'Haasan']),\n",
       " WordList(['Haasan', '’']),\n",
       " WordList(['’', 's']),\n",
       " WordList(['s', 'political']),\n",
       " WordList(['political', 'campaign']),\n",
       " WordList(['campaign', 'under']),\n",
       " WordList(['under', 'the']),\n",
       " WordList(['the', 'aegis']),\n",
       " WordList(['aegis', 'of']),\n",
       " WordList(['of', 'his']),\n",
       " WordList(['his', 'party']),\n",
       " WordList(['party', 'Makkal']),\n",
       " WordList(['Makkal', 'Needhi']),\n",
       " WordList(['Needhi', 'Maiam']),\n",
       " WordList(['Maiam', 'MNM'])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(example_text).ngrams(2) # Bigrams - two words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frequency is simply the ratio of the count of a word present in a sentence, to the length of the sentence.\n",
    "\n",
    "Therefore, we can generalize term frequency as:\n",
    "\n",
    "TF = (Number of times term T appears in the particular row) / (number of terms in that row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'of': 3, 'in': 3, 'IPAC': 2, 'also': 2, 'vice': 1, 'that': 1, 'Kamal': 1, 'handled': 1, 'Earlier': 1, 'Incidentally,': 1, 'his': 1, 'Needhi': 1, 'Banerjee': 1, 'under': 1, 'film': 1, 'Dal': 1, 'Sources': 1, 'aegis': 1, 'had': 1, 'Haasan’s': 1, 'Chennai': 1, 'subject': 1, '2021.': 1, 'week,': 1, 'Makkal': 1, 'confirmed': 1, 'handling': 1, 'be': 1, 'party,': 1, 'Assembly': 1, 'campaign': 1, 'founder': 1, 'Minister': 1, 'Janata': 1, 'and': 1, 'Mamata': 1, 'Chief': 1, 'president.': 1, '(MNM).': 1, 'personality': 1, 'Maiam': 1, '(U)': 1, 'met': 1, 'with': 1, 'some': 1, 'aspects': 1, 'would': 1, 'last': 1, 'political': 1, 'State': 1, 'Bengal': 1, 'West': 1, 'has': 1, 'polls': 1}\n"
     ]
    }
   ],
   "source": [
    "# <function <lambda> at 0x7f0310160668> - error\n",
    "import pandas as pd\n",
    "\n",
    "# word Frequency to Dictionary\n",
    "def tfx(x):\n",
    "    word = pd.value_counts(x.split(\" \"))\n",
    "    i=0\n",
    "    dict = {}\n",
    "    for x in word:\n",
    "        #print(word.index[i], word[i])\n",
    "        dict[word.index[i]] = word[i]\n",
    "        i = i+1\n",
    "    return dict\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(tfx(example_text))\n",
    "\n",
    "dict2 = tfx(example_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Document Frequency\n",
    "The intuition behind inverse document frequency (IDF) is that a word is not of much use to us if it’s appearing in all the documents.\n",
    "\n",
    "Therefore, the IDF of each word is the log of the ratio of the total number of rows to the number of rows in which that word is present.\n",
    "\n",
    "IDF = log(N/n), where, N is the total number of rows and n is the number of rows in which the word was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.127,\n",
       " 'of': 0.055,\n",
       " 'in': 0.055,\n",
       " 'IPAC': 0.036,\n",
       " 'also': 0.036,\n",
       " 'vice': 0.018,\n",
       " 'that': 0.018,\n",
       " 'Kamal': 0.018,\n",
       " 'handled': 0.018,\n",
       " 'Earlier': 0.018,\n",
       " 'Incidentally,': 0.018,\n",
       " 'his': 0.018,\n",
       " 'Needhi': 0.018,\n",
       " 'Banerjee': 0.018,\n",
       " 'under': 0.018,\n",
       " 'film': 0.018,\n",
       " 'Dal': 0.018,\n",
       " 'Sources': 0.018,\n",
       " 'aegis': 0.018,\n",
       " 'had': 0.018,\n",
       " 'Haasan’s': 0.018,\n",
       " 'Chennai': 0.018,\n",
       " 'subject': 0.018,\n",
       " '2021.': 0.018,\n",
       " 'week,': 0.018,\n",
       " 'Makkal': 0.018,\n",
       " 'confirmed': 0.018,\n",
       " 'handling': 0.018,\n",
       " 'be': 0.018,\n",
       " 'party,': 0.018,\n",
       " 'Assembly': 0.018,\n",
       " 'campaign': 0.018,\n",
       " 'founder': 0.018,\n",
       " 'Minister': 0.018,\n",
       " 'Janata': 0.018,\n",
       " 'and': 0.018,\n",
       " 'Mamata': 0.018,\n",
       " 'Chief': 0.018,\n",
       " 'president.': 0.018,\n",
       " '(MNM).': 0.018,\n",
       " 'personality': 0.018,\n",
       " 'Maiam': 0.018,\n",
       " '(U)': 0.018,\n",
       " 'met': 0.018,\n",
       " 'with': 0.018,\n",
       " 'some': 0.018,\n",
       " 'aspects': 0.018,\n",
       " 'would': 0.018,\n",
       " 'last': 0.018,\n",
       " 'political': 0.018,\n",
       " 'State': 0.018,\n",
       " 'Bengal': 0.018,\n",
       " 'West': 0.018,\n",
       " 'has': 0.018,\n",
       " 'polls': 0.018}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idf -\n",
    "# The more the value of IDF, the more unique is the word.\n",
    "# tf1['words']\n",
    "tfDict = {}\n",
    "DictCount = len(dict2)\n",
    "for word, count in dict2.items():\n",
    "        tfDict[word] = round(count/float(DictCount),3)\n",
    "        \n",
    "tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.895,\n",
       " 'of': 1.263,\n",
       " 'in': 1.263,\n",
       " 'IPAC': 1.439,\n",
       " 'also': 1.439,\n",
       " 'vice': 1.74,\n",
       " 'that': 1.74,\n",
       " 'Kamal': 1.74,\n",
       " 'handled': 1.74,\n",
       " 'Earlier': 1.74,\n",
       " 'Incidentally,': 1.74,\n",
       " 'his': 1.74,\n",
       " 'Needhi': 1.74,\n",
       " 'Banerjee': 1.74,\n",
       " 'under': 1.74,\n",
       " 'film': 1.74,\n",
       " 'Dal': 1.74,\n",
       " 'Sources': 1.74,\n",
       " 'aegis': 1.74,\n",
       " 'had': 1.74,\n",
       " 'Haasan’s': 1.74,\n",
       " 'Chennai': 1.74,\n",
       " 'subject': 1.74,\n",
       " '2021.': 1.74,\n",
       " 'week,': 1.74,\n",
       " 'Makkal': 1.74,\n",
       " 'confirmed': 1.74,\n",
       " 'handling': 1.74,\n",
       " 'be': 1.74,\n",
       " 'party,': 1.74,\n",
       " 'Assembly': 1.74,\n",
       " 'campaign': 1.74,\n",
       " 'founder': 1.74,\n",
       " 'Minister': 1.74,\n",
       " 'Janata': 1.74,\n",
       " 'and': 1.74,\n",
       " 'Mamata': 1.74,\n",
       " 'Chief': 1.74,\n",
       " 'president.': 1.74,\n",
       " '(MNM).': 1.74,\n",
       " 'personality': 1.74,\n",
       " 'Maiam': 1.74,\n",
       " '(U)': 1.74,\n",
       " 'met': 1.74,\n",
       " 'with': 1.74,\n",
       " 'some': 1.74,\n",
       " 'aspects': 1.74,\n",
       " 'would': 1.74,\n",
       " 'last': 1.74,\n",
       " 'political': 1.74,\n",
       " 'State': 1.74,\n",
       " 'Bengal': 1.74,\n",
       " 'West': 1.74,\n",
       " 'has': 1.74,\n",
       " 'polls': 1.74}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDF - COmpute\n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    N = len(docList)\n",
    "    idfDict = {}\n",
    "    #print(docList)\n",
    "    for word, val in docList.items():\n",
    "        #print(word,val, N)\n",
    "        idfDict[word] = round(math.log10(N / float(val)),3)\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "idfs = computeIDF(dict2)\n",
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPAC</th>\n",
       "      <td>1.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>1.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamal</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earlier</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incidentally,</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Needhi</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banerjee</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dal</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sources</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aegis</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haasan’s</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chennai</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week,</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Makkal</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirmed</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handling</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party,</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assembly</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founder</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minister</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Janata</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mamata</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chief</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president.</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MNM).</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personality</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maiam</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(U)</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspects</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bengal</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polls</th>\n",
       "      <td>1.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IDF\n",
       "the            0.895\n",
       "of             1.263\n",
       "in             1.263\n",
       "IPAC           1.439\n",
       "also           1.439\n",
       "vice           1.740\n",
       "that           1.740\n",
       "Kamal          1.740\n",
       "handled        1.740\n",
       "Earlier        1.740\n",
       "Incidentally,  1.740\n",
       "his            1.740\n",
       "Needhi         1.740\n",
       "Banerjee       1.740\n",
       "under          1.740\n",
       "film           1.740\n",
       "Dal            1.740\n",
       "Sources        1.740\n",
       "aegis          1.740\n",
       "had            1.740\n",
       "Haasan’s       1.740\n",
       "Chennai        1.740\n",
       "subject        1.740\n",
       "2021.          1.740\n",
       "week,          1.740\n",
       "Makkal         1.740\n",
       "confirmed      1.740\n",
       "handling       1.740\n",
       "be             1.740\n",
       "party,         1.740\n",
       "Assembly       1.740\n",
       "campaign       1.740\n",
       "founder        1.740\n",
       "Minister       1.740\n",
       "Janata         1.740\n",
       "and            1.740\n",
       "Mamata         1.740\n",
       "Chief          1.740\n",
       "president.     1.740\n",
       "(MNM).         1.740\n",
       "personality    1.740\n",
       "Maiam          1.740\n",
       "(U)            1.740\n",
       "met            1.740\n",
       "with           1.740\n",
       "some           1.740\n",
       "aspects        1.740\n",
       "would          1.740\n",
       "last           1.740\n",
       "political      1.740\n",
       "State          1.740\n",
       "Bengal         1.740\n",
       "West           1.740\n",
       "has            1.740\n",
       "polls          1.740"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame.from_dict(idfs,  orient='index', columns=['IDF'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 6.265000000000001,\n",
       " 'of': 3.7889999999999997,\n",
       " 'in': 3.7889999999999997,\n",
       " 'IPAC': 2.878,\n",
       " 'also': 2.878,\n",
       " 'vice': 1.74,\n",
       " 'that': 1.74,\n",
       " 'Kamal': 1.74,\n",
       " 'handled': 1.74,\n",
       " 'Earlier': 1.74,\n",
       " 'Incidentally,': 1.74,\n",
       " 'his': 1.74,\n",
       " 'Needhi': 1.74,\n",
       " 'Banerjee': 1.74,\n",
       " 'under': 1.74,\n",
       " 'film': 1.74,\n",
       " 'Dal': 1.74,\n",
       " 'Sources': 1.74,\n",
       " 'aegis': 1.74,\n",
       " 'had': 1.74,\n",
       " 'Haasan’s': 1.74,\n",
       " 'Chennai': 1.74,\n",
       " 'subject': 1.74,\n",
       " '2021.': 1.74,\n",
       " 'week,': 1.74,\n",
       " 'Makkal': 1.74,\n",
       " 'confirmed': 1.74,\n",
       " 'handling': 1.74,\n",
       " 'be': 1.74,\n",
       " 'party,': 1.74,\n",
       " 'Assembly': 1.74,\n",
       " 'campaign': 1.74,\n",
       " 'founder': 1.74,\n",
       " 'Minister': 1.74,\n",
       " 'Janata': 1.74,\n",
       " 'and': 1.74,\n",
       " 'Mamata': 1.74,\n",
       " 'Chief': 1.74,\n",
       " 'president.': 1.74,\n",
       " '(MNM).': 1.74,\n",
       " 'personality': 1.74,\n",
       " 'Maiam': 1.74,\n",
       " '(U)': 1.74,\n",
       " 'met': 1.74,\n",
       " 'with': 1.74,\n",
       " 'some': 1.74,\n",
       " 'aspects': 1.74,\n",
       " 'would': 1.74,\n",
       " 'last': 1.74,\n",
       " 'political': 1.74,\n",
       " 'State': 1.74,\n",
       " 'Bengal': 1.74,\n",
       " 'West': 1.74,\n",
       " 'has': 1.74,\n",
       " 'polls': 1.74}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf\n",
    "\n",
    "tfidf = computeTFIDF(dict2, idfs)\n",
    "tfidf\n",
    "\n",
    "#tfDict\n",
    "\n",
    "# TF * IDF = TFIDF\n",
    "# DIct2 * IDFS = TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency – Inverse Document Frequency (TF-IDF)\n",
    "# TF-IDF is the multiplication of the TF and IDF which we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse matrices offer the data structure to store large, \n",
    "#sparse matrices, and allows us to perform complex matrix computations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021', 'aegis', 'also', 'and', 'aspects', 'assembly', 'banerjee', 'be', 'bengal', 'campaign', 'chennai', 'chief', 'confirmed', 'dal', 'earlier', 'film', 'founder', 'haasan', 'had', 'handled', 'handling', 'has', 'his', 'in', 'incidentally', 'ipac', 'janata', 'kamal', 'last', 'maiam', 'makkal', 'mamata', 'met', 'minister', 'mnm', 'needhi', 'of', 'party', 'personality', 'political', 'polls', 'president', 'some', 'sources', 'state', 'subject', 'that', 'the', 'under', 'vice', 'week', 'west', 'with', 'would']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = sent_tokenize(example_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "response = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 23 10 12 46 47 45 53  7 20 36  5 40 44  0 47 14 28 50 51  8 11 33 31\n",
      "  6 18  2 32 52 25 16  3 26 13 49 41 47 36  2 25 24 21 19 42  4 15 38 27\n",
      " 17 39  9 48  1 22 37 30 35 29 34]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sources'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(response.nonzero()[1])\n",
    "\n",
    "feature_names[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sources  ->  0.19\n",
      "in  ->  0.58\n",
      "chennai  ->  0.19\n",
      "confirmed  ->  0.19\n",
      "that  ->  0.19\n",
      "the  ->  0.45\n",
      "subject  ->  0.19\n",
      "would  ->  0.19\n",
      "be  ->  0.19\n",
      "handling  ->  0.19\n",
      "of  ->  0.15\n",
      "assembly  ->  0.19\n",
      "polls  ->  0.19\n",
      "state  ->  0.19\n",
      "2021  ->  0.19\n",
      "the  ->  0.45\n",
      "the  ->  0.45\n",
      "of  ->  0.15\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for col in response.nonzero()[1]:\n",
    "    if (response[0, col]) > 0:\n",
    "        print (feature_names[col], ' -> ', round( (response[0, col]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mayank408/TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words\n",
    "nstead, we need to convert the text to numbers.\n",
    "\n",
    "We may want to perform classification of documents, so each document is an “input” and a class label is the “output” for our predictive algorithm. Algorithms take vectors of numbers as input, therefore we need to convert documents to fixed-length vectors of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19188367 0.         0.         0.         0.         0.19188367\n",
      "  0.         0.19188367 0.         0.         0.19188367 0.\n",
      "  0.19188367 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19188367 0.         0.         0.57565101\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14593248 0.         0.         0.         0.19188367 0.\n",
      "  0.         0.19188367 0.19188367 0.19188367 0.19188367 0.45331834\n",
      "  0.         0.         0.         0.         0.         0.19188367]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "#text = [example_text] # as a List \n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#text = [example_text] # as a List Note\n",
    "\n",
    "text = sent_tokenize(example_text)\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize \n",
    "##print(vectorizer.vocabulary_) # Id number\n",
    "#print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "#print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sources  ->  0.19\n",
      "in  ->  0.58\n",
      "chennai  ->  0.19\n",
      "confirmed  ->  0.19\n",
      "that  ->  0.19\n",
      "the  ->  0.45\n",
      "subject  ->  0.19\n",
      "would  ->  0.19\n",
      "be  ->  0.19\n",
      "handling  ->  0.19\n",
      "of  ->  0.15\n",
      "assembly  ->  0.19\n",
      "polls  ->  0.19\n",
      "state  ->  0.19\n",
      "2021  ->  0.19\n",
      "the  ->  0.45\n",
      "the  ->  0.45\n",
      "of  ->  0.15\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for col in response.nonzero()[1]:\n",
    "    if (response[0, col]) > 0:\n",
    "        print (feature_names[col], ' -> ', round( (response[0, col]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x37 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bi  and n-gram\n",
    "count_vec = CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                            ngram_range=(2, 2), max_df=1.0, min_df=0.0, max_features=None)\n",
    "\n",
    "#none\n",
    "count_train = count_vec.fit(text)\n",
    "bag_of_words = count_vec.transform(text)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.575651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.453318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirmed</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sources</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polls</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handling</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chennai</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assembly</th>\n",
       "      <td>0.191884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.145932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnm</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needhi</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personality</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chief</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minister</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspects</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>west</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banerjee</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mamata</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makkal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earlier</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>founder</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haasan</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handled</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bengal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incidentally</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipac</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>janata</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aegis</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maiam</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kamal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfidf\n",
       "in            0.575651\n",
       "the           0.453318\n",
       "2021          0.191884\n",
       "confirmed     0.191884\n",
       "that          0.191884\n",
       "subject       0.191884\n",
       "state         0.191884\n",
       "sources       0.191884\n",
       "polls         0.191884\n",
       "handling      0.191884\n",
       "would         0.191884\n",
       "chennai       0.191884\n",
       "be            0.191884\n",
       "assembly      0.191884\n",
       "of            0.145932\n",
       "some          0.000000\n",
       "mnm           0.000000\n",
       "needhi        0.000000\n",
       "party         0.000000\n",
       "personality   0.000000\n",
       "political     0.000000\n",
       "president     0.000000\n",
       "chief         0.000000\n",
       "minister      0.000000\n",
       "aspects       0.000000\n",
       "and           0.000000\n",
       "also          0.000000\n",
       "under         0.000000\n",
       "vice          0.000000\n",
       "week          0.000000\n",
       "west          0.000000\n",
       "with          0.000000\n",
       "banerjee      0.000000\n",
       "met           0.000000\n",
       "mamata        0.000000\n",
       "makkal        0.000000\n",
       "dal           0.000000\n",
       "earlier       0.000000\n",
       "film          0.000000\n",
       "founder       0.000000\n",
       "haasan        0.000000\n",
       "had           0.000000\n",
       "handled       0.000000\n",
       "campaign      0.000000\n",
       "has           0.000000\n",
       "his           0.000000\n",
       "bengal        0.000000\n",
       "incidentally  0.000000\n",
       "ipac          0.000000\n",
       "janata        0.000000\n",
       "aegis         0.000000\n",
       "last          0.000000\n",
       "maiam         0.000000\n",
       "kamal         0.000000"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#text = [example_text] # as a List Note\n",
    "\n",
    "text = sent_tokenize(example_text)\n",
    "\n",
    "#instantiate CountVectorizer()\n",
    "cv=CountVectorizer()\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(text)\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"tf_idf_weights\"])\n",
    " \n",
    "# sort ascending\n",
    "#df_idf.sort_values(by=['tf_idf_weights'])\n",
    "\n",
    "# count matrix\n",
    "count_vector=cv.transform(text)\n",
    " \n",
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "feature_names = cv.get_feature_names()\n",
    " \n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    " \n",
    "#print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
